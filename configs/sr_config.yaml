dataset:
  scale: 4
  subset: #/home/dev/data_main/CORESETS/vmlinuz.txt
  workers: 10
  train_portion: 0.2
  batch_size: 32
  crop_size: 32 # small image,  40x4=160, pathces are 200x200
  files_list:  /home/dev/data_main/SR/train_sets_txt/
  debug_mode: True # run on a small porion of data
  
arch:
  channels: 3
  c_fixed: 36
  scale: 4
  arch_pattern: 
      head: 2
      skip: 1
      tail: 2
      body: 3
      upsample: 1
  body_cells: 1

env:
  run_name: 'DEBUG'
  gpu: 0
  log_dir: /home/dev/data_main/LOGS/SR/
  im_dir: 'arch_images'  
  workers: 4 
  seed : 777 
  print_freq: 60 # print frequency
 
search:
  penalty: 0.0
  use_adjuster: false
  unrolled: false
  use_l1_alpha: false
  l1_lambda: 1
  use_soft_edge: false
  alpha_selector: softmax #softmax #gumbel2k
  warm_up: 0
  lr_scheduler: cosine
  w_lr: 1e-3 # lr for weights
  w_lr_min: 0.001 # minimum lr for weights
  w_momentum: 0.9 # momentum for weights
  w_weight_decay: 3e-6 # weight decay for weights
  w_grad_clip: 5 # gradient clipping for weights
  epochs: 1 # n of training epochs
  temperature_start: 1e1
  temp_red: 0.6
  alpha_lr:  3e-4 #3e-4 #lr for alpha
  alpha_weight_decay: 0 #1e-3 #weight decay for alpha
  train_portion: 0.5  # portion of training data
  adjuster: 
    lr: 0.001
    CL: 2e+7
    CH: 1e+8 # set some big value if no upper bound 
    max_iter: 100
    verbose: true
    gamma: 1e-6
  
train:
  lr_scheduler: linear
  batch_size : 16 # batch size
  lr : 1e-3 # lr for weights
  weight_decay : 0 # weight decay
  print_freq : 200 # print frequency
  epochs : 1 # # of training epochs
  genotype_path: "/home/dev/data_mnt/logs/DEBUG/search/trail_1/SEARCH_batch experiment_penalty_0_trail_1-2021-10-20-12/best_arch.gen"
